{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecaff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Downloading rasterio-1.5.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting geopandas\n",
      "  Using cached geopandas-1.1.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Using cached affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs (from rasterio)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: certifi in /home/abdullah/miniconda3/lib/python3.13/site-packages (from rasterio) (2026.1.4)\n",
      "Collecting click!=8.2.*,>=4.0 (from rasterio)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=2 in /home/abdullah/miniconda3/lib/python3.13/site-packages (from rasterio) (2.4.0)\n",
      "Collecting pyparsing (from rasterio)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.12.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: packaging in /home/abdullah/miniconda3/lib/python3.13/site-packages (from geopandas) (25.0)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/abdullah/miniconda3/lib/python3.13/site-packages (from geopandas) (2.3.3)\n",
      "Collecting pyproj>=3.5.0 (from geopandas)\n",
      "  Downloading pyproj-3.7.2-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Downloading shapely-2.1.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/abdullah/miniconda3/lib/python3.13/site-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/abdullah/miniconda3/lib/python3.13/site-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/abdullah/miniconda3/lib/python3.13/site-packages (from pandas>=2.0.0->geopandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/abdullah/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
      "Downloading rasterio-1.5.0-cp313-cp313-manylinux_2_28_x86_64.whl (37.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached geopandas-1.1.2-py3-none-any.whl (341 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading pyogrio-0.12.1-cp313-cp313-manylinux_2_28_x86_64.whl (32.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.5/32.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.7.2-cp313-cp313-manylinux_2_28_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.1.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Installing collected packages: shapely, pyproj, pyparsing, pyogrio, click, attrs, affine, cligj, rasterio, geopandas\n",
      "\u001b[2K  Attempting uninstall: click╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [pyogrio]\n",
      "\u001b[2K    Found existing installation: click 8.2.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [pyogrio]\n",
      "\u001b[2K    Uninstalling click-8.2.1:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [pyogrio]\n",
      "\u001b[2K      Successfully uninstalled click-8.2.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [pyogrio]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [geopandas]10\u001b[0m [geopandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed affine-2.4.0 attrs-25.4.0 click-8.3.1 cligj-0.7.2 geopandas-1.1.2 pyogrio-0.12.1 pyparsing-3.3.2 pyproj-3.7.2 rasterio-1.5.0 shapely-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8959df8d-bc4a-45f3-bd7f-a189b2e834ce",
   "metadata": {
    "id": "8959df8d-bc4a-45f3-bd7f-a189b2e834ce"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import requests\n",
    "import zipfile\n",
    "import glob\n",
    "import shutil\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "# from osgeo import gdal, ogr, osr\n",
    "from pathlib import Path\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from bmi_topography import Topography\n",
    "from landlab.io import esri_ascii, write_esri_ascii\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from landlab import imshowhs_grid, imshow_grid, imshow_grid_at_node\n",
    "from matplotlib.colors import ListedColormap\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c49a98de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/amehedi/Downloads/ml_debris/output/USGS10m_34.10807234417825_-119.76797422272267_34.801871827638045_-118.84756453755563_reproj_26911_clipped_resampled.asc'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "repo_root = \"/home/abdullah/fire-debrisflow-ml\"\n",
    "src_path = os.path.join(repo_root, \"src\")\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "from pipeline import load_config, ensure_utm_aoi, process_dem\n",
    "from dem import fetch_dem\n",
    "\n",
    "cfg = load_config(\"/home/abdullah/fire-debrisflow-ml/config/base.yaml\")\n",
    "aoi_path, target_crs = ensure_utm_aoi(cfg[\"aoi\"][\"aoi\"])\n",
    "output_dir = cfg[\"paths\"][\"output_dir\"]\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "dem_path = fetch_dem(aoi_path, cfg.get(\"dem\", {}), output_dir)\n",
    "dem_ascii, template_meta = process_dem(\n",
    "    dem_path,\n",
    "    aoi_path,\n",
    "    target_crs,\n",
    "    cfg[\"raster\"][\"target_res\"],\n",
    "    output_dir,\n",
    ")\n",
    "\n",
    "dem_ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a57cf-7aa6-4e14-b185-bf681653a3e2",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1764803232905,
     "user": {
      "displayName": "Abdullah Al Mehedi (Himel)",
      "userId": "09059070858976426842"
     },
     "user_tz": 480
    },
    "id": "c06a57cf-7aa6-4e14-b185-bf681653a3e2"
   },
   "outputs": [],
   "source": [
    "# ---- Config-driven inputs ----\n",
    "config_path = \"/home/abdullah/fire-debrisflow-ml/config/base.yaml\"  # <-- CHANGE THIS\n",
    "with open(config_path, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "clip_shapefile = cfg[\"aoi\"][\"aoi\"]\n",
    "target_resolution = cfg[\"raster\"][\"target_res\"]\n",
    "output_dir = cfg[\"paths\"][\"output_dir\"]\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fire_name = cfg[\"fire\"][\"name\"]\n",
    "fire_id = cfg[\"fire\"][\"id\"]\n",
    "\n",
    "dem_cfg = cfg.get(\"dem\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc85d62c-ea5a-46a2-b789-f8ea008ba7be",
   "metadata": {
    "id": "cc85d62c-ea5a-46a2-b789-f8ea008ba7be"
   },
   "outputs": [],
   "source": [
    "# Load shapefile\n",
    "gdf = gpd.read_file(clip_shapefile)\n",
    "\n",
    "# Run a check to ensure shapefile is in UTM projection\n",
    "if \"UTM zone\" in gdf.crs.to_wkt():\n",
    "    # Already in UTM - just store EPSG code\n",
    "    epsg_code = gdf.crs.to_epsg()\n",
    "    crs = f\"EPSG:{epsg_code}\"\n",
    "    print(f\"Shapefile already in UTM: {crs}\")\n",
    "else:\n",
    "    # If shapefile not in UTM projection\n",
    "    # Convert to WGS84 first to get centroid in lon/lat\n",
    "    centroid = gdf.to_crs(epsg=4326).geometry.unary_union.centroid\n",
    "    zone = int((centroid.x + 180) / 6) + 1\n",
    "    crs = f\"EPSG:326{zone}\"\n",
    "\n",
    "    # Reproject and overwrite the shapefile\n",
    "    gdf = gdf.to_crs(crs)\n",
    "    gdf.to_file(clip_shapefile, driver=\"ESRI Shapefile\")\n",
    "\n",
    "print(\"CRS:\", crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253cea4-091f-41e8-8ad3-da845c3110b3",
   "metadata": {
    "id": "c253cea4-091f-41e8-8ad3-da845c3110b3"
   },
   "outputs": [],
   "source": [
    "# ---- Download USGS ~10m DEM using bmi-topography package ----\n",
    "bounds = gpd.read_file(clip_shapefile).to_crs(epsg=4326).total_bounds\n",
    "west, south, east, north = bounds\n",
    "b = dem_cfg.get(\"buffer_deg\", 0.05)\n",
    "\n",
    "topo = Topography(\n",
    "    dem_type=dem_cfg.get(\"dem_type\", \"USGS10m\"),\n",
    "    south=south - b,\n",
    "    north=north + b,\n",
    "    west=west - b,\n",
    "    east=east + b,\n",
    "    output_format=dem_cfg.get(\"output_format\", \"GTiff\"),\n",
    "    cache_dir=dem_cfg.get(\"cache_dir\", output_dir),\n",
    "    api_key=dem_cfg.get(\"api_key\"),\n",
    ")\n",
    "fname = topo.fetch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee339bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756bad7e-91bb-4b2d-894a-d65669e3b6d2",
   "metadata": {
    "id": "756bad7e-91bb-4b2d-894a-d65669e3b6d2"
   },
   "outputs": [],
   "source": [
    "# ---- Reproject raster ----\n",
    "def reproject_raster_to_match_crs(src_path, target_crs_epsg, resampling_method, template_meta=None):\n",
    "    resampling_dict = {\n",
    "        'nearest': Resampling.nearest,\n",
    "        'bilinear': Resampling.bilinear,\n",
    "        'cubic': Resampling.cubic,\n",
    "        'average': Resampling.average,\n",
    "        'mode': Resampling.mode\n",
    "    }\n",
    "    resampling_enum = resampling_dict.get(resampling_method, Resampling.nearest)\n",
    "\n",
    "    with rasterio.open(src_path) as src:\n",
    "        dst_crs = f\"EPSG:{target_crs_epsg}\"\n",
    "        if template_meta is None:\n",
    "            transform, width, height = calculate_default_transform(\n",
    "                src.crs, dst_crs, src.width, src.height, *src.bounds\n",
    "            )\n",
    "        else:\n",
    "            # Snap to DEM grid\n",
    "            transform = template_meta['transform']\n",
    "            width = template_meta['width']\n",
    "            height = template_meta['height']\n",
    "\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({'crs': dst_crs, 'transform': transform, 'width': width, 'height': height})\n",
    "\n",
    "        reprojected_path = src_path.replace('.tif', f'_reproj_{target_crs_epsg}.tif')\n",
    "        with rasterio.open(reprojected_path, 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=resampling_enum\n",
    "                )\n",
    "    return reprojected_path\n",
    "\n",
    "\n",
    "# ---- Clip raster ----\n",
    "def clip_raster_to_shape(raster_path, shapefile_path, template_meta=None):\n",
    "    with fiona.open(shapefile_path, \"r\") as shapefile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        out_image, out_transform = mask(src, shapes, crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "\n",
    "    if template_meta is not None:\n",
    "        # Snap clipped raster to DEM grid exactly\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": template_meta['height'],\n",
    "            \"width\": template_meta['width'],\n",
    "            \"transform\": template_meta['transform']\n",
    "        })\n",
    "    else:\n",
    "        # For DEM (first raster)\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "\n",
    "    clipped_path = raster_path.replace('.tif', '_clipped.tif')\n",
    "    with rasterio.open(clipped_path, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "    return clipped_path\n",
    "\n",
    "\n",
    "# ---- Resample raster ----\n",
    "def resample_raster(raster_path, template_meta=None, resampling_method='nearest', target_resolution=None):\n",
    "    resampling_dict = {\n",
    "        'nearest': Resampling.nearest,\n",
    "        'bilinear': Resampling.bilinear,\n",
    "        'cubic': Resampling.cubic,\n",
    "        'average': Resampling.average,\n",
    "        'mode': Resampling.mode\n",
    "    }\n",
    "    resampling_enum = resampling_dict.get(resampling_method, Resampling.nearest)\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        kwargs = src.meta.copy()\n",
    "\n",
    "        if template_meta is not None:\n",
    "            # Snap resampled grid to DEM alignment\n",
    "            transform = template_meta['transform']\n",
    "            width = template_meta['width']\n",
    "            height = template_meta['height']\n",
    "        else:\n",
    "            transform = src.transform\n",
    "            width = src.width\n",
    "            height = src.height\n",
    "            if target_resolution is not None:\n",
    "                scale_x = src.res[0] / target_resolution\n",
    "                scale_y = src.res[1] / target_resolution\n",
    "                width = int(src.width * scale_x)\n",
    "                height = int(src.height * scale_y)\n",
    "                transform = rasterio.Affine(\n",
    "                    target_resolution, transform.b, transform.c,\n",
    "                    transform.d, -target_resolution, transform.f\n",
    "                )\n",
    "\n",
    "        kwargs.update({'transform': transform, 'width': width, 'height': height})\n",
    "\n",
    "        resampled_path = raster_path.replace('.tif', f'_resampled.tif')\n",
    "        with rasterio.open(resampled_path, 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=src.crs,\n",
    "                    resampling=resampling_enum\n",
    "                )\n",
    "    return resampled_path\n",
    "\n",
    "\n",
    "# ---- Convert to ASCII ----\n",
    "def convert_to_ascii(tif_path, out_dir, template_meta=None):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        array = src.read(1)\n",
    "        meta = template_meta if template_meta is not None else src.meta\n",
    "\n",
    "        transform = meta['transform']\n",
    "        width = meta['width']\n",
    "        height = meta['height']\n",
    "\n",
    "        xllcorner = transform[2]\n",
    "        yllcorner = transform[5] + transform[4] * (height - 1) if transform[4] < 0 else transform[5] - transform[4] * (height - 1)\n",
    "        cellsize = abs(transform[0])\n",
    "\n",
    "        nodata_value = src.nodata if src.nodata is not None else -9999.0\n",
    "\n",
    "        ascii_path = os.path.join(out_dir, os.path.basename(tif_path).replace('.tif', '.asc'))\n",
    "        with open(ascii_path, 'w') as f:\n",
    "            f.write(f\"ncols         {width}\\n\")\n",
    "            f.write(f\"nrows         {height}\\n\")\n",
    "            f.write(f\"xllcorner     {xllcorner}\\n\")\n",
    "            f.write(f\"yllcorner     {yllcorner}\\n\")\n",
    "            f.write(f\"cellsize      {cellsize}\\n\")\n",
    "            f.write(f\"NODATA_value  {nodata_value}\\n\")\n",
    "            for row in array:\n",
    "                row_out = [str(nodata_value) if np.isnan(v) else str(v) for v in row]\n",
    "                f.write(\" \".join(row_out) + \"\\n\")\n",
    "    return ascii_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc078108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from pathlib import Path\n",
    "\n",
    "# fire_name = 'Bolt Creek'\n",
    "# fire_id = 'WA4772812134620220910' \n",
    "\n",
    "# fire_name_fmt = fire_name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "# fire_id_fmt = fire_id.lower()\n",
    "\n",
    "# base_url = \"https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/MTBS_Fire/data/baer/\"\n",
    "# out_dir = Path(\"burn_severity\")\n",
    "# out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# # Possible BAER/MTBS zip URLs\n",
    "# candidates = [\n",
    "#     f\"{base_url}{fire_name_fmt}_sbs.zip\",\n",
    "#     f\"{base_url}{fire_name_fmt}_{fire_id_fmt}_sbs.zip\",\n",
    "# ]\n",
    "\n",
    "# for url in candidates:\n",
    "#     r = requests.get(url, stream=True)\n",
    "#     if r.status_code == 200:\n",
    "#         out_path = out_dir / url.split(\"/\")[-1]\n",
    "#         with open(out_path, \"wb\") as f:\n",
    "#             for chunk in r.iter_content(chunk_size=8192):\n",
    "#                 f.write(chunk)\n",
    "#         print(f\"Downloaded: {out_path}\")\n",
    "#         break\n",
    "# else:\n",
    "#     raise RuntimeError(\"Burn severity zip not found for given fire.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963b74d-b1a0-4ba7-b1be-0d1b086674bd",
   "metadata": {
    "id": "3963b74d-b1a0-4ba7-b1be-0d1b086674bd"
   },
   "outputs": [],
   "source": [
    "# ---- Build URL/resampling map from config ----\n",
    "urls = {}\n",
    "\n",
    "for name, info in cfg.get(\"feature_sources\", {}).get(\"rasters\", {}).items():\n",
    "    url = info[\"url\"]\n",
    "    urls[url] = info.get(\"resampling\", cfg[\"raster\"][\"resampling_method\"])\n",
    "\n",
    "for name, info in cfg.get(\"feature_sources\", {}).get(\"landcover\", {}).items():\n",
    "    url = info[\"url\"]\n",
    "    urls[url] = info.get(\"resampling\", \"nearest\")\n",
    "\n",
    "bs = cfg.get(\"burn_severity\", {})\n",
    "src = bs.get(\"source\", \"local\").lower()\n",
    "if src == \"local\":\n",
    "    local_path = os.path.join(bs[\"local\"][\"path\"], bs[\"local\"][\"filename\"])\n",
    "    urls[local_path] = bs[\"local\"].get(\"resampling\", \"nearest\")\n",
    "else:\n",
    "    base_url = bs[\"remote\"][\"base_url\"]\n",
    "    fire_name_fmt = fire_name.lower().replace(\" \", \"_\")\n",
    "    fire_id_fmt = fire_id.lower()\n",
    "    for pattern in bs[\"remote\"][\"candidates\"]:\n",
    "        url = pattern.format(\n",
    "            base_url=base_url,\n",
    "            fire_name_fmt=fire_name_fmt,\n",
    "            fire_id_fmt=fire_id_fmt,\n",
    "        )\n",
    "        urls[url] = bs[\"remote\"].get(\"resampling\", \"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06630c75-3115-41c4-b3a6-5fe00633351a",
   "metadata": {
    "id": "06630c75-3115-41c4-b3a6-5fe00633351a",
    "outputId": "a31c3ef2-09e3-4ed7-c100-637ff7021006"
   },
   "outputs": [],
   "source": [
    "# ---- Create a list for storing output file names ----\n",
    "ascii_files = []\n",
    "\n",
    "# ---- Process DEM first ----\n",
    "dem_reproj = reproject_raster_to_match_crs(str(fname), target_crs_epsg=crs.split(':')[1], resampling_method='cubic')\n",
    "dem_clipped = clip_raster_to_shape(dem_reproj, clip_shapefile)\n",
    "dem_resampled = resample_raster(dem_clipped, template_meta=None, resampling_method='cubic', target_resolution=target_resolution)\n",
    "dem_ascii = convert_to_ascii(dem_resampled, output_dir, template_meta=None)\n",
    "\n",
    "with rasterio.open(dem_resampled) as src:\n",
    "    template_meta = src.meta.copy()  # lock DEM grid as template\n",
    "\n",
    "# ---- Storing ASCII file names as we create them into a list so adding them to the model grid later requires no effort from the user ----\n",
    "ascii_files.append(dem_ascii)\n",
    "\n",
    "# ---- Process all other rasters ----\n",
    "for url, method in urls.items():\n",
    "    local_path = None\n",
    "\n",
    "    # Handle ZIP input\n",
    "    if url.lower().endswith(\".zip\"):\n",
    "        zip_filename = os.path.join(output_dir, os.path.basename(url))\n",
    "        extract_dir = os.path.join(output_dir, \"unzipped\")\n",
    "\n",
    "        for attempt in range(5):\n",
    "            try:\n",
    "                mode, downloaded = ('ab', os.path.getsize(zip_filename)) if os.path.exists(zip_filename) else ('wb', 0)\n",
    "                headers = {\"Range\": f\"bytes={downloaded}-\"} if downloaded else {}\n",
    "\n",
    "                with requests.get(url, headers=headers, stream=True, timeout=60) as r:\n",
    "                    r.raise_for_status()\n",
    "                    total_size = int(r.headers.get(\"Content-Length\", 0)) + downloaded\n",
    "                    with open(zip_filename, mode) as f:\n",
    "                        for chunk in r.iter_content(chunk_size=1024 * 1024 * 50):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                                downloaded += len(chunk)\n",
    "                if downloaded >= total_size:\n",
    "                    break\n",
    "            except Exception:\n",
    "                time.sleep(5)\n",
    "        else:\n",
    "            print(f\"Failed to download {url}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(extract_dir):\n",
    "            with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_dir)\n",
    "\n",
    "        tif_files = [os.path.join(root, f)\n",
    "                     for root, _, files in os.walk(extract_dir)\n",
    "                     for f in files if f.lower().endswith(\".tif\")]\n",
    "        if not tif_files:\n",
    "            continue\n",
    "        local_path = tif_files[0]\n",
    "\n",
    "    # Handle TIFF input\n",
    "    elif url.lower().endswith(\".tif\"):\n",
    "        if url.startswith(\"http\"):\n",
    "            local_path = os.path.join(output_dir, os.path.basename(url))\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            if not os.path.exists(local_path):\n",
    "                try:\n",
    "                    r = requests.get(url, stream=True, timeout=60)\n",
    "                    r.raise_for_status()\n",
    "                    with open(local_path, 'wb') as f:\n",
    "                        for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "                            f.write(chunk)\n",
    "                except Exception as e:\n",
    "                    print(f\"Download failed for {url}: {e}\")\n",
    "                    continue\n",
    "        else:\n",
    "            local_path = url\n",
    "    else:\n",
    "        print(f\"Check file type: {url}\")\n",
    "        continue\n",
    "\n",
    "    # ---- Process and snap to DEM grid ----\n",
    "    try:\n",
    "        reprojected = reproject_raster_to_match_crs(local_path, target_crs_epsg=crs.split(':')[1], resampling_method=method, template_meta=template_meta)\n",
    "        resampled = resample_raster(reprojected, template_meta=template_meta, resampling_method=method, target_resolution=target_resolution)\n",
    "        clipped = clip_raster_to_shape(resampled, clip_shapefile, template_meta=template_meta)\n",
    "        ascii_file = convert_to_ascii(clipped, output_dir, template_meta=template_meta)\n",
    "        ascii_files.append(ascii_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed processing {local_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ---- Remove intermediate files ----\n",
    "    for item in os.listdir(output_dir):\n",
    "        item_path = os.path.join(output_dir, item)\n",
    "        try:\n",
    "            if os.path.isfile(item_path) and item_path.lower().endswith(('.tif', '.zip')):\n",
    "                os.remove(item_path)\n",
    "            elif os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not delete {item_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def _read_ascii_header(path):\n",
    "    header = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for _ in range(6):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                header[parts[0].lower()] = float(parts[1])\n",
    "    return header\n",
    "\n",
    "def sanity_check_ascii(paths, tol=1e-6, strict=True):\n",
    "    if not paths:\n",
    "        raise ValueError(\"No ASCII paths provided.\")\n",
    "    headers = {p: _read_ascii_header(p) for p in paths}\n",
    "\n",
    "    ref_path = paths[0]\n",
    "    ref = headers[ref_path]\n",
    "    keys = [\"ncols\", \"nrows\", \"cellsize\", \"xllcorner\", \"yllcorner\"]\n",
    "\n",
    "    mismatches = []\n",
    "    for p, h in headers.items():\n",
    "        for k in keys:\n",
    "            if k not in h or k not in ref:\n",
    "                mismatches.append((p, k, \"missing\", \"missing\"))\n",
    "                break\n",
    "            v = h[k]\n",
    "            rv = ref[k]\n",
    "            same = math.isclose(v, rv, rel_tol=0, abs_tol=tol)\n",
    "            if not same:\n",
    "                mismatches.append((p, k, v, rv))\n",
    "                break\n",
    "\n",
    "    if mismatches:\n",
    "        print(f\"Grid mismatch vs template: {ref_path}\")\n",
    "        for p, k, v, rv in mismatches:\n",
    "            print(f\"- {p} -> {k}: {v} (ref {rv})\")\n",
    "        if strict:\n",
    "            raise ValueError(\"ASCII grid mismatch\")\n",
    "    else:\n",
    "        print(f\"All {len(paths)} ASCII files match the template grid.\")\n",
    "\n",
    "sanity_check_ascii(ascii_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62f2ea-bbe3-4375-b154-d15cdf0b955f",
   "metadata": {
    "id": "4f62f2ea-bbe3-4375-b154-d15cdf0b955f",
    "outputId": "043046ab-a1e4-47f4-f853-31f7eb8cf9d5"
   },
   "outputs": [],
   "source": [
    "ascii_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from landlab.io import esri_ascii\n",
    "\n",
    "ascii_files = [\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/USGS10m_48.25657366943968_-120.70648297891194_48.38314763488489_-120.54768702340596_reproj_32610_clipped_resampled.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/cec7_0_cm_p_reproj_32610_resampled_clipped.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/anylithicdpt_cm_p_reproj_32610_resampled_clipped.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/claytotal_0_cm_p_reproj_32610_resampled_clipped.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/ph1to1h2o_0_cm_p_reproj_32610_resampled_clipped.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/sandtotal_0_cm_p_reproj_32610_resampled_clipped.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/silttotal_0_cm_p_reproj_32610_resampled_clipped.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/dbovendry_0_cm_p_reproj_32610_resampled_clipped.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/Annual_NLCD_LndCov_2021_CU_C1V1_reproj_32610_resampled_clipped.asc\",\n",
    "    \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/pioneer_wa4818312053120240608_sbs_reproj_32610_resampled_clipped.asc\",\n",
    "]\n",
    "\n",
    "def _read_nodata(ascii_path, default=-9999.0):\n",
    "    nodata_val = None\n",
    "    with open(ascii_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "                nodata_val = float(line.split()[1])\n",
    "                break\n",
    "    return default if nodata_val is None else nodata_val\n",
    "\n",
    "def _load_vals(ascii_path, field_name):\n",
    "    with open(ascii_path, \"r\") as f:\n",
    "        g = esri_ascii.load(f, name=field_name)\n",
    "    return g.at_node[field_name].copy()\n",
    "\n",
    "# 0) DEM -> master grid\n",
    "nodata = _read_nodata(ascii_files[0])\n",
    "with open(ascii_files[0], \"r\") as f:\n",
    "    grid = esri_ascii.load(f, name=\"topographic__elevation\")\n",
    "elev = grid.at_node[\"topographic__elevation\"]\n",
    "grid.set_nodata_nodes_to_closed(elev, nodata)\n",
    "\n",
    "# 1) CEC (scale /10)\n",
    "nodata = _read_nodata(ascii_files[1])\n",
    "cec = _load_vals(ascii_files[1], \"cation__exchange_capacity\")\n",
    "grid.add_field(\"cation__exchange_capacity\", cec / 10, at=\"node\", clobber=True)\n",
    "grid.set_nodata_nodes_to_closed(cec, nodata)\n",
    "\n",
    "# 2) Soil thickness (scale /100)\n",
    "nodata = _read_nodata(ascii_files[2])\n",
    "hs = _load_vals(ascii_files[2], \"soil__thickness\")\n",
    "grid.add_field(\"soil__thickness\", hs / 100, at=\"node\", clobber=True)\n",
    "grid.set_nodata_nodes_to_closed(hs, nodata)\n",
    "\n",
    "# 3) Clay\n",
    "nodata = _read_nodata(ascii_files[3])\n",
    "cl = _load_vals(ascii_files[3], \"clay__total\")\n",
    "grid.add_field(\"clay__total\", cl, at=\"node\", clobber=True)\n",
    "grid.set_nodata_nodes_to_closed(cl, nodata)\n",
    "\n",
    "# 4) pH (scale /100)\n",
    "nodata = _read_nodata(ascii_files[4])\n",
    "ph = _load_vals(ascii_files[4], \"pH\")\n",
    "grid.add_field(\"pH\", ph / 100, at=\"node\", clobber=True)\n",
    "grid.set_nodata_nodes_to_closed(ph, nodata)\n",
    "\n",
    "# 5) Sand\n",
    "nodata = _read_nodata(ascii_files[5])\n",
    "sa = _load_vals(ascii_files[5], \"sand__total\")\n",
    "grid.add_field(\"sand__total\", sa, at=\"node\", clobber=True)\n",
    "grid.set_nodata_nodes_to_closed(sa, nodata)\n",
    "\n",
    "# 6) Silt\n",
    "nodata = _read_nodata(ascii_files[6])\n",
    "si = _load_vals(ascii_files[6], \"silt__total\")\n",
    "grid.add_field(\"silt__total\", si, at=\"node\", clobber=True)\n",
    "grid.set_nodata_nodes_to_closed(si, nodata)\n",
    "\n",
    "# 7) Dry bulk density (scale /100)\n",
    "nodata = _read_nodata(ascii_files[7])\n",
    "db = _load_vals(ascii_files[7], \"dry__bulk_density\")\n",
    "grid.add_field(\"dry__bulk_density\", db / 100, at=\"node\", clobber=True)\n",
    "grid.set_nodata_nodes_to_closed(db, nodata)\n",
    "\n",
    "# 8) Landcover (close nodata + class 11)\n",
    "nodata = _read_nodata(ascii_files[8])\n",
    "lc = _load_vals(ascii_files[8], \"landcover\")\n",
    "grid.add_field(\"landcover\", lc, at=\"node\", clobber=True)\n",
    "grid.set_nodata_nodes_to_closed(lc, nodata)\n",
    "grid.set_nodata_nodes_to_closed(lc, 11)\n",
    "\n",
    "# 9) Burn severity (reclass)\n",
    "nodata = _read_nodata(ascii_files[9])\n",
    "bs = _load_vals(ascii_files[9], \"burn__severity\")\n",
    "bs[~np.isin(bs, [2, 3, 4])] = 1\n",
    "grid.add_field(\"burn__severity\", bs, at=\"node\", clobber=True)\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0912fe-22ae-4a16-8f2a-e6dd525b72bb",
   "metadata": {
    "id": "1f0912fe-22ae-4a16-8f2a-e6dd525b72bb"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "\n",
    "with open(ascii_files[0], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[0]) as f:\n",
    "    grid = esri_ascii.load(f, name=\"topographic__elevation\")\n",
    "\n",
    "elev = grid.at_node[\"topographic__elevation\"]\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(elev, nodata_val)\n",
    "\n",
    "os.rename(ascii_files[0], os.path.join(os.path.dirname(ascii_files[0]), \"topographic__elevation.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3d2c2-4352-4578-a64e-e53195090491",
   "metadata": {
    "id": "acb3d2c2-4352-4578-a64e-e53195090491"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[1], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[1]) as f:\n",
    "    grid_1 = esri_ascii.load(f, name=\"cation__exchange_capacity\")\n",
    "\n",
    "cec = grid_1.at_node[\"cation__exchange_capacity\"]\n",
    "\n",
    "_=grid.add_field('cation__exchange_capacity', cec/10, at='node', clobber=True)\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(cec, nodata_val)\n",
    "\n",
    "os.rename(ascii_files[1], os.path.join(os.path.dirname(ascii_files[1]), \"cation__exchange_capacity.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a3ee9-4ef7-446e-b5be-45e882ae6a18",
   "metadata": {
    "id": "f19a3ee9-4ef7-446e-b5be-45e882ae6a18"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[2], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[2]) as f:\n",
    "    grid_2 = esri_ascii.load(f, name=\"soil__thickness\")\n",
    "\n",
    "hs = grid_2.at_node[\"soil__thickness\"]\n",
    "\n",
    "_=grid.add_field('soil__thickness', hs/100, at='node', clobber=True)\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(hs, nodata_val)\n",
    "\n",
    "os.rename(ascii_files[2], os.path.join(os.path.dirname(ascii_files[2]), \"soil__thickness.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b1df9-31f5-41dc-a9db-1bcc27e93501",
   "metadata": {
    "id": "977b1df9-31f5-41dc-a9db-1bcc27e93501"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[3], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[3]) as f:\n",
    "    grid_3 = esri_ascii.load(f, name=\"clay__total\")\n",
    "\n",
    "cl = grid_3.at_node[\"clay__total\"]\n",
    "\n",
    "_=grid.add_field('clay__total', cl, at='node', clobber=True)\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(cl, nodata_val)\n",
    "\n",
    "os.rename(ascii_files[3], os.path.join(os.path.dirname(ascii_files[3]), \"clay__total.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f0d68-a251-4dd9-9b9f-b42bd08c92f0",
   "metadata": {
    "id": "2d8f0d68-a251-4dd9-9b9f-b42bd08c92f0"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[4], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[4]) as f:\n",
    "    grid_4 = esri_ascii.load(f, name=\"pH\")\n",
    "\n",
    "ph = grid_4.at_node[\"pH\"]\n",
    "\n",
    "_=grid.add_field('pH', ph/100, at='node', clobber=True)\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(ph, nodata_val)\n",
    "\n",
    "os.rename(ascii_files[4], os.path.join(os.path.dirname(ascii_files[4]), \"pH.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06436cd-a6d7-4414-ac6d-9304264ba22e",
   "metadata": {
    "id": "e06436cd-a6d7-4414-ac6d-9304264ba22e"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[5], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[5]) as f:\n",
    "    grid_5 = esri_ascii.load(f, name=\"sand__total\")\n",
    "\n",
    "sa = grid_5.at_node[\"sand__total\"]\n",
    "\n",
    "_=grid.add_field('sand__total', sa, at='node', clobber=True)\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(sa, nodata_val)\n",
    "\n",
    "os.rename(ascii_files[5], os.path.join(os.path.dirname(ascii_files[5]), \"sand__total.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f4b94-37f9-4972-9746-cd37c0b9230f",
   "metadata": {
    "id": "dd9f4b94-37f9-4972-9746-cd37c0b9230f"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[6], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[6]) as f:\n",
    "    grid_6 = esri_ascii.load(f, name=\"silt__total\")\n",
    "\n",
    "si = grid_6.at_node[\"silt__total\"]\n",
    "\n",
    "_=grid.add_field('silt__total', si, at='node', clobber=True)\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(si, nodata_val)\n",
    "\n",
    "os.rename(ascii_files[6], os.path.join(os.path.dirname(ascii_files[6]), \"silt__total.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7b053-5c00-4213-b2f6-49b55a5d78fe",
   "metadata": {
    "id": "0fe7b053-5c00-4213-b2f6-49b55a5d78fe"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[7], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[7]) as f:\n",
    "    grid_7 = esri_ascii.load(f, name=\"dry__bulk_density\")\n",
    "\n",
    "db = grid_7.at_node[\"dry__bulk_density\"]\n",
    "\n",
    "_=grid.add_field('dry__bulk_density', db/100, at='node', clobber=True)\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(db, nodata_val)\n",
    "\n",
    "os.rename(ascii_files[7], os.path.join(os.path.dirname(ascii_files[7]), \"dry__bulk_density.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e9ac9-a94c-422f-8873-79c5b4bd0b24",
   "metadata": {
    "id": "be0e9ac9-a94c-422f-8873-79c5b4bd0b24"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[8], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[8]) as f:\n",
    "    grid_8 = esri_ascii.load(f, name=\"landcover\")\n",
    "\n",
    "C = grid_8.at_node[\"landcover\"]\n",
    "\n",
    "_=grid.add_field('landcover', C, at='node', clobber=True)\n",
    "\n",
    "grid.set_nodata_nodes_to_closed(C, nodata_val)\n",
    "grid.set_nodata_nodes_to_closed(C, 11)\n",
    "\n",
    "os.rename(ascii_files[8], os.path.join(os.path.dirname(ascii_files[8]), \"landcover.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a3634-6c30-4ac9-9039-3fd87a7a6153",
   "metadata": {
    "id": "0a6a3634-6c30-4ac9-9039-3fd87a7a6153"
   },
   "outputs": [],
   "source": [
    "# Open ASCII file and record the NO_DATA value\n",
    "# Load data as grid\n",
    "# Store Data in RasterModelGrid format and add as field to grid\n",
    "# close nodes at NO_DATA cells\n",
    "# rename file to fit Landlab nomenclature ('your__field_name')\n",
    "with open(ascii_files[9], \"r\") as f:\n",
    "    nodata_val = None\n",
    "    for line in f:\n",
    "        if line.strip().upper().startswith(\"NODATA_VALUE\"):\n",
    "            nodata_val = float(line.split()[1])\n",
    "            break\n",
    "if nodata_val is None:\n",
    "   nodata_val = -9999.\n",
    "\n",
    "with open(ascii_files[9]) as f:\n",
    "    grid_9 = esri_ascii.load(f, name=\"burn__severity\")\n",
    "\n",
    "bs = grid_9.at_node[\"burn__severity\"]\n",
    "\n",
    "bs[~np.isin(bs, [2, 3, 4])] = 1\n",
    "\n",
    "_=grid.add_field('burn__severity', bs, at='node', clobber=True)\n",
    "\n",
    "os.rename(ascii_files[9], os.path.join(os.path.dirname(ascii_files[9]), \"burn__severity.asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97448cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "repo_root = Path(\"/home/abdullah/fire-debrisflow-ml\")\n",
    "sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "from landlab_io import load_grid, add_ascii_field, read_nodata_value, write_ascii_field\n",
    "from soil_features import (\n",
    "    compute_ksat,\n",
    "    compute_transmissivity,\n",
    "    compute_saturated_water_content,\n",
    "    compute_soil_texture,\n",
    "    compute_fc_wp_arrays,\n",
    "    compute_soil_density,\n",
    ")\n",
    "from vegetation_features import rootcohesion, adjust_internal_friction_angle, compute_cohesion, vegtype\n",
    "\n",
    "cfg = yaml.safe_load(open(repo_root / \"config\" / \"base.yaml\", \"r\"))\n",
    "out_dir = Path(cfg[\"paths\"][\"output_dir\"])\n",
    "\n",
    "# Auto-detect DEM (original name or renamed)\n",
    "dem_path = next(out_dir.glob(\"*USGS10m*_clipped_resampled.asc\"), None)\n",
    "if dem_path is None:\n",
    "    dem_path = out_dir / \"topographic__elevation.asc\"\n",
    "\n",
    "if not dem_path.exists():\n",
    "    raise FileNotFoundError(f\"DEM not found in {out_dir}\")\n",
    "\n",
    "def burn_reclass(vals):\n",
    "    vals = np.asarray(vals).copy()\n",
    "    vals[~np.isin(vals, [2, 3, 4])] = 1\n",
    "    return vals\n",
    "\n",
    "# Load DEM -> master grid\n",
    "grid = load_grid(str(dem_path), \"topographic__elevation\")\n",
    "nodata = read_nodata_value(str(dem_path))\n",
    "grid.set_nodata_nodes_to_closed(grid.at_node[\"topographic__elevation\"], nodata)\n",
    "\n",
    "# Rename DEM if not already\n",
    "dem_renamed = out_dir / \"topographic__elevation.asc\"\n",
    "if dem_path != dem_renamed and dem_path.exists():\n",
    "    os.rename(dem_path, dem_renamed)\n",
    "\n",
    "# Source files (use renamed files if present, else original)\n",
    "def pick_file(renamed, original_glob):\n",
    "    renamed_path = out_dir / renamed\n",
    "    if renamed_path.exists():\n",
    "        return renamed_path\n",
    "    found = next(out_dir.glob(original_glob), None)\n",
    "    if found is None:\n",
    "        raise FileNotFoundError(f\"Missing {renamed} or {original_glob}\")\n",
    "    return found\n",
    "\n",
    "sources = [\n",
    "    (pick_file(\"cation__exchange_capacity.asc\", \"*cec7_0_cm*_clipped.asc\"), \"cation__exchange_capacity\", dict(scale=0.1)),\n",
    "    (pick_file(\"soil__thickness.asc\", \"*anylithicdpt_cm*_clipped.asc\"), \"soil__thickness\", dict(scale=0.01)),\n",
    "    (pick_file(\"clay__total.asc\", \"*claytotal_0_cm*_clipped.asc\"), \"clay__total\", dict()),\n",
    "    (pick_file(\"pH.asc\", \"*ph1to1h2o_0_cm*_clipped.asc\"), \"pH\", dict(scale=0.01)),\n",
    "    (pick_file(\"sand__total.asc\", \"*sandtotal_0_cm*_clipped.asc\"), \"sand__total\", dict()),\n",
    "    (pick_file(\"silt__total.asc\", \"*silttotal_0_cm*_clipped.asc\"), \"silt__total\", dict()),\n",
    "    (pick_file(\"dry__bulk_density.asc\", \"*dbovendry_0_cm*_clipped.asc\"), \"dry__bulk_density\", dict(scale=0.01)),\n",
    "    (pick_file(\"landcover.asc\", \"*NLCD*clipped.asc\"), \"landcover\", dict(extra_close_values=[11])),\n",
    "    (pick_file(\"burn__severity.asc\", \"*_sbs*_clipped.asc\"), \"burn__severity\", dict(close_nodata=False, transform=burn_reclass)),\n",
    "]\n",
    "\n",
    "for path, field_name, kwargs in sources:\n",
    "    add_ascii_field(grid, str(path), field_name, rename_file=True, **kwargs)\n",
    "\n",
    "# Derived features + outputs\n",
    "ksat = compute_ksat(\n",
    "    grid.at_node[\"pH\"],\n",
    "    grid.at_node[\"clay__total\"],\n",
    "    grid.at_node[\"silt__total\"],\n",
    "    grid.at_node[\"cation__exchange_capacity\"],\n",
    ")\n",
    "grid.add_field(\n",
    "    \"soil__saturated_hydraulic_conductivity\",\n",
    "    (ksat / 100) * 10,\n",
    "    at=\"node\",\n",
    "    clobber=True,\n",
    ")\n",
    "write_ascii_field(str(out_dir / \"soil__saturated_hydraulic_conductivity.asc\"), grid, \"soil__saturated_hydraulic_conductivity\")\n",
    "\n",
    "trans = compute_transmissivity(\n",
    "    grid.at_node[\"soil__saturated_hydraulic_conductivity\"],\n",
    "    grid.at_node[\"soil__thickness\"],\n",
    ")\n",
    "grid.add_field(\"soil__transmissivity\", trans, at=\"node\", clobber=True)\n",
    "write_ascii_field(str(out_dir / \"soil__transmissivity.asc\"), grid, \"soil__transmissivity\")\n",
    "\n",
    "wsat = compute_saturated_water_content(\n",
    "    grid.at_node[\"dry__bulk_density\"],\n",
    "    grid.at_node[\"clay__total\"],\n",
    "    grid.at_node[\"silt__total\"],\n",
    ")\n",
    "grid.add_field(\"saturated__water_content\", wsat, at=\"node\", clobber=True)\n",
    "write_ascii_field(str(out_dir / \"saturated__water_content.asc\"), grid, \"saturated__water_content\")\n",
    "\n",
    "soil_texture = compute_soil_texture(\n",
    "    grid.at_node[\"sand__total\"],\n",
    "    grid.at_node[\"silt__total\"],\n",
    "    grid.at_node[\"clay__total\"],\n",
    ")\n",
    "grid.add_field(\"soil__texture\", soil_texture, at=\"node\", clobber=True)\n",
    "write_ascii_field(str(out_dir / \"soil__texture.asc\"), grid, \"soil__texture\")\n",
    "\n",
    "porosity, theta_fc, theta_wp, phi = compute_fc_wp_arrays(\n",
    "    grid.at_node[\"soil__texture\"],\n",
    "    grid.at_node[\"saturated__water_content\"],\n",
    ")\n",
    "grid.add_field(\"field__capacity\", theta_fc, at=\"node\", clobber=True)\n",
    "grid.add_field(\"wilting__point\", theta_wp, at=\"node\", clobber=True)\n",
    "grid.add_field(\"porosity\", porosity, at=\"node\", clobber=True)\n",
    "grid.add_field(\"soil__internal_friction_angle\", phi, at=\"node\", clobber=True)\n",
    "\n",
    "if \"landcover\" in grid.at_node:\n",
    "    grid.at_node[\"soil__internal_friction_angle\"] = adjust_internal_friction_angle(\n",
    "        grid.at_node[\"landcover\"],\n",
    "        grid.at_node[\"soil__internal_friction_angle\"],\n",
    "    )\n",
    "\n",
    "write_ascii_field(str(out_dir / \"field__capacity.asc\"), grid, \"field__capacity\")\n",
    "write_ascii_field(str(out_dir / \"wilting__point.asc\"), grid, \"wilting__point\")\n",
    "write_ascii_field(str(out_dir / \"porosity.asc\"), grid, \"porosity\")\n",
    "write_ascii_field(str(out_dir / \"soil__internal_friction_angle.asc\"), grid, \"soil__internal_friction_angle\")\n",
    "\n",
    "density = compute_soil_density(grid.at_node[\"dry__bulk_density\"], grid.at_node[\"porosity\"])\n",
    "grid.add_field(\"soil__density\", density, at=\"node\", clobber=True)\n",
    "write_ascii_field(str(out_dir / \"soil__density.asc\"), grid, \"soil__density\")\n",
    "\n",
    "if \"landcover\" in grid.at_node:\n",
    "    landcover = grid.at_node[\"landcover\"]\n",
    "    grid.add_field(\"landcovercolor\", rootcohesion(landcover, 0, 1, 2, 3, 4, 5), at=\"node\", clobber=True)\n",
    "\n",
    "    c_min, c_mode, c_max = compute_cohesion(landcover)\n",
    "    grid.add_field(\"soil__minimum_total_cohesion\", c_min, at=\"node\", clobber=True)\n",
    "    grid.add_field(\"soil__maximum_total_cohesion\", c_max, at=\"node\", clobber=True)\n",
    "    grid.add_field(\"soil__mode_total_cohesion\", c_mode, at=\"node\", clobber=True)\n",
    "    write_ascii_field(str(out_dir / \"soil__minimum_total_cohesion.asc\"), grid, \"soil__minimum_total_cohesion\")\n",
    "    write_ascii_field(str(out_dir / \"soil__maximum_total_cohesion.asc\"), grid, \"soil__maximum_total_cohesion\")\n",
    "    write_ascii_field(str(out_dir / \"soil__mode_total_cohesion.asc\"), grid, \"soil__mode_total_cohesion\")\n",
    "\n",
    "    vegetation_type = vegtype(landcover, -9999.0, 3, 2, 1, 0)\n",
    "    grid.add_field(\"vegetation__plant_functional_type\", vegetation_type, at=\"node\", clobber=True)\n",
    "    write_ascii_field(str(out_dir / \"vegetation__plant_functional_type.asc\"), grid, \"vegetation__plant_functional_type\")\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483776aa-aac7-45e8-9a7c-7e9cd60d1064",
   "metadata": {
    "id": "483776aa-aac7-45e8-9a7c-7e9cd60d1064"
   },
   "outputs": [],
   "source": [
    "# Compute Ksat as a function of pH, Clay and Silt percent mass totals, and cation exchange capacity\n",
    "ksat = 10**(0.40220 + (0.26122 * grid.at_node['pH']) + 0.44565 - (0.02329 * grid.at_node['clay__total']) - (0.01265 * grid.at_node['silt__total']) - (0.01038 * grid.at_node['cation__exchange_capacity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d5699-513c-41ac-8fa6-f1dd442cd1a2",
   "metadata": {
    "id": "694d5699-513c-41ac-8fa6-f1dd442cd1a2"
   },
   "outputs": [],
   "source": [
    "# Store Ksat in grid at node\n",
    "_=grid.add_field('soil__saturated_hydraulic_conductivity', (ksat/100)*10, at='node', clobber=True) #m/day, includes lateral flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1c9ea-7616-4462-929c-15a41fa3b77e",
   "metadata": {
    "id": "b6e1c9ea-7616-4462-929c-15a41fa3b77e",
    "outputId": "67ff4641-40e2-47b9-93af-699ee4850f38"
   },
   "outputs": [],
   "source": [
    "# Store Ksat in output directory as ASCII\n",
    "write_esri_ascii(os.path.join(output_dir, 'soil__saturated_hydraulic_conductivity.asc'), grid, 'soil__saturated_hydraulic_conductivity', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af06b02-a2f0-4ba7-8cef-5fe01ff531ab",
   "metadata": {
    "id": "4af06b02-a2f0-4ba7-8cef-5fe01ff531ab"
   },
   "outputs": [],
   "source": [
    "# Compute transmissivity as a function of Ksat and soil thickness\n",
    "To=grid.at_node['soil__saturated_hydraulic_conductivity']*grid.at_node['soil__thickness'] #m^2/day\n",
    "\n",
    "# To avoid division by 0 errors\n",
    "for i in range(len(To)):\n",
    "    if To[i] < 0.1:\n",
    "        To[i] = 0.1\n",
    "\n",
    "# Store Ksat in grid at node\n",
    "_=grid.add_field('soil__transmissivity', To, at='node', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bad1df-d975-47eb-b30e-4257c6fa2872",
   "metadata": {
    "id": "83bad1df-d975-47eb-b30e-4257c6fa2872",
    "outputId": "138311e8-54ca-498c-f3fc-6b2c2c4cbc65"
   },
   "outputs": [],
   "source": [
    "# Store transmissivity in output directory as ASCII\n",
    "write_esri_ascii(os.path.join(output_dir, 'soil__transmissivity.asc'), grid, 'soil__transmissivity', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1add180-b337-4e90-b68f-5bb4bc8486ff",
   "metadata": {
    "id": "a1add180-b337-4e90-b68f-5bb4bc8486ff"
   },
   "outputs": [],
   "source": [
    "# Compute saturated water content as a function of dry bulk density, Clay and Silt percent mass totals\n",
    "wsat = 0.83080 - (0.28217 * grid.at_node['dry__bulk_density']) + (0.0002728 * grid.at_node['clay__total']) + (0.000187 * grid.at_node['silt__total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8105c44-456b-481c-92b7-5b16b85fc33f",
   "metadata": {
    "id": "f8105c44-456b-481c-92b7-5b16b85fc33f"
   },
   "outputs": [],
   "source": [
    "# Store in grid at node\n",
    "_=grid.add_field('saturated__water_content', wsat, at='node', clobber=True) #volume fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd8d1d-fbd5-441a-8797-bf0ef6d8d3e2",
   "metadata": {
    "id": "3cdd8d1d-fbd5-441a-8797-bf0ef6d8d3e2",
    "outputId": "44f14c52-3e3a-40ff-be0e-cd700a72dc88"
   },
   "outputs": [],
   "source": [
    "# Store in output directory as ASCII\n",
    "write_esri_ascii(os.path.join(output_dir, 'saturated__water_content.asc'), grid, 'saturated__water_content', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c9159-2b1f-4229-9187-ff63020e61c2",
   "metadata": {
    "id": "292c9159-2b1f-4229-9187-ff63020e61c2"
   },
   "outputs": [],
   "source": [
    "# Classify soil texture from total mass % of sand, clay, and/or silt\n",
    "# using classification thresholds outlined in the USDA soil textural triangle\n",
    "def classify_soil_texture(sand, silt, clay):\n",
    "    if sand >= 85 and (silt + 1.5 * clay) < 15:\n",
    "        return 1\n",
    "    elif sand >= 70 and sand <= 91 and (silt + 1.5 * clay) >= 15 and (silt + 2 * clay) < 30:\n",
    "        return 2\n",
    "    elif clay >= 7 and clay <= 20 and sand > 52 and (silt + 2 * clay) >= 30:\n",
    "        return 3\n",
    "    elif clay < 7 and silt < 50 and sand > 43:\n",
    "        return 3\n",
    "    elif clay >= 7 and clay <= 27 and silt >= 28 and silt <= 50 and sand <= 52:\n",
    "        return 4\n",
    "    elif clay >= 12 and clay <= 27 and silt >= 50:\n",
    "        return 5\n",
    "    elif clay < 12 and silt <= 80 and silt >= 50:\n",
    "        return 5\n",
    "    elif clay < 12 and silt >= 80:\n",
    "        return 6\n",
    "    elif clay >= 20 and clay <= 35 and silt < 28 and sand > 45:\n",
    "        return 7\n",
    "    elif clay >= 27 and clay <= 40 and sand < 46 and sand > 20:\n",
    "        return 8\n",
    "    elif clay >= 27 and clay <= 40 and sand <= 20:\n",
    "        return 9\n",
    "    elif clay >= 35 and sand >= 45:\n",
    "        return 10\n",
    "    elif clay >= 40 and sand >= 40:\n",
    "        return 11\n",
    "    elif clay >= 40 and sand <= 45 and silt < 40:\n",
    "        return 12\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3bede-7ca1-4e03-8374-96d481805b18",
   "metadata": {
    "id": "8db3bede-7ca1-4e03-8374-96d481805b18"
   },
   "outputs": [],
   "source": [
    "soil_types = [\n",
    "    classify_soil_texture(\n",
    "        grid.at_node['sand__total'][i],\n",
    "        grid.at_node['silt__total'][i],\n",
    "        grid.at_node['clay__total'][i]\n",
    "    )\n",
    "    for i in range(len(grid.at_node['sand__total']))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99775993-4804-4f0b-9b00-6b72d1df248f",
   "metadata": {
    "id": "99775993-4804-4f0b-9b00-6b72d1df248f"
   },
   "outputs": [],
   "source": [
    "# store in grid at node\n",
    "_=grid.add_field('soil__texture', soil_types, at='node', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449ba5c-b88a-46bb-9146-b74f6cdba506",
   "metadata": {
    "id": "a449ba5c-b88a-46bb-9146-b74f6cdba506",
    "outputId": "37abb332-b03d-4b2d-f6a6-3e291657656f"
   },
   "outputs": [],
   "source": [
    "# Store in output directory as ASCII\n",
    "write_esri_ascii(os.path.join(output_dir, 'soil__texture.asc'), grid, 'soil__texture', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553367d2-c57d-40d9-a660-704ba578e246",
   "metadata": {
    "id": "553367d2-c57d-40d9-a660-704ba578e246"
   },
   "outputs": [],
   "source": [
    "# Lookup Table\n",
    "# Uses literature consensus mapping for converting from USDA soil texture classification\n",
    "# to Unified Soil Classification System (USCS) to estimate internal friction angle\n",
    "# Uses Dingman Physical Hydrology (Second Edition) to calculate porosity, field capacity,\n",
    "# and wilting point\n",
    "def classify_fc_wp(soil_texture, saturated_water_content):\n",
    "\n",
    "    psi_fc = 3.33 #m\n",
    "    psi_wp = 350 #m\n",
    "\n",
    "    if soil_texture == 1: #USDA - sand; USCS - SP (Poorly graded sand)\n",
    "        phi = 30\n",
    "        porosity = 0.395\n",
    "        theta_fc = porosity*((.121/psi_fc)**(1/4.05))\n",
    "        theta_wp = porosity*((.121/psi_wp)**(1/4.05))\n",
    "    elif soil_texture == 2: #USDA - loamy sand; USCS - SM (silty sand/sand-silt mixtures)\n",
    "        phi = 30\n",
    "        porosity = 0.410\n",
    "        theta_fc = porosity*((.090/psi_fc)**(1/4.38))\n",
    "        theta_wp = porosity*((.090/psi_wp)**(1/4.38))\n",
    "    elif soil_texture == 3: #USDA - sandy loam; USCS - SM (silty sand/sand-silt mixtures)\n",
    "        phi = 30\n",
    "        porosity = 0.435\n",
    "        theta_fc = porosity*((.218/psi_fc)**(1/4.90))\n",
    "        theta_wp = porosity*((.218/psi_wp)**(1/4.90))\n",
    "    elif soil_texture == 4: # USDA - loam; USCS - CL (inorganic clays, gravelly sandy or silty)\n",
    "        phi = 31\n",
    "        porosity = 0.451\n",
    "        theta_fc = porosity*((.478/psi_fc)**(1/5.39))\n",
    "        theta_wp = porosity*((.478/psi_wp)**(1/5.39))\n",
    "    elif soil_texture == 5: #USDA - silt loam; USCS - ML (inorganic silt, clayey silt)\n",
    "        phi = 31\n",
    "        porosity = 0.485\n",
    "        theta_fc = porosity*((.786/psi_fc)**(1/5.30))\n",
    "        theta_wp = porosity*((.786/psi_wp)**(1/5.30))\n",
    "    elif soil_texture == 6: #silt; estimated from Dingman Physical Hydrology 3rd Edition Figures 8.2 (field capacity), 8.4 (wilting point)\n",
    "        # USDA - silt; USCS - ML (inorganic silt, clayey silt)\n",
    "        phi = 31\n",
    "        porosity = saturated_water_content if saturated_water_content is not None else -9999.\n",
    "        theta_fc = 0.2\n",
    "        theta_wp = 0.075\n",
    "    elif soil_texture == 7: #USDA - sandy clay loam; USCS - SC (clayey sand)\n",
    "        phi = 27\n",
    "        porosity = 0.420\n",
    "        theta_fc = porosity*((.299/psi_fc)**(1/7.12))\n",
    "        theta_wp = porosity*((.299/psi_wp)**(1/7.12))\n",
    "    elif soil_texture == 8: #USDA - clay loam; USCS - CL (inorganic clays, gravelly sandy or silty)\n",
    "        phi = 16\n",
    "        porosity = 0.476\n",
    "        theta_fc = porosity*((.630/psi_fc)**(1/8.52))\n",
    "        theta_wp = porosity*((.630/psi_wp)**(1/8.52))\n",
    "    elif soil_texture == 9: #USDA - silty clay loam; USCS - CL (inorganic clays, gravelly sandy or silty)\n",
    "        phi = 16\n",
    "        porosity = 0.477\n",
    "        theta_fc = porosity*((.356/psi_fc)**(1/7.75))\n",
    "        theta_wp = porosity*((.356/psi_wp)**(1/7.75))\n",
    "    elif soil_texture == 10: #USDA - sandy clay; USCS - SC (clayey sand)\n",
    "        phi = 27\n",
    "        porosity = 0.426\n",
    "        theta_fc = porosity*((.153/psi_fc)**(1/10.4))\n",
    "        theta_wp = porosity*((.153/psi_wp)**(1/10.4))\n",
    "    elif soil_texture == 11: #USDA - silty clay; USCS - CH (inorganic fat clays)\n",
    "        phi = 16\n",
    "        porosity = 0.492\n",
    "        theta_fc = porosity*((.490/psi_fc)**(1/10.4))\n",
    "        theta_wp = porosity*((.490/psi_wp)**(1/10.4))\n",
    "    elif soil_texture == 12: #USDA - clay; USCS - CH (inorganic fat clays)\n",
    "        phi = 16\n",
    "        porosity = 0.482\n",
    "        theta_fc = porosity*((.405/psi_fc)**(1/11.4))\n",
    "        theta_wp = porosity*((.405/psi_wp)**(1/11.4))\n",
    "    else:\n",
    "        porosity = -9999.\n",
    "        theta_fc = -9999.\n",
    "        theta_wp = -9999.\n",
    "        phi = -9999.\n",
    "\n",
    "    return porosity, theta_fc, theta_wp, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27a3f0-a473-4d80-bc14-e224f8166c54",
   "metadata": {
    "id": "0b27a3f0-a473-4d80-bc14-e224f8166c54"
   },
   "outputs": [],
   "source": [
    "soil_porosity, soil_theta_fc, soil_theta_wp, internal_friction_angle = zip(*[\n",
    "    classify_fc_wp(grid.at_node['soil__texture'][i], grid.at_node['saturated__water_content'][i])\n",
    "    for i in range(len(grid.at_node['soil__texture']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90338168-0d47-42a2-8f79-32cedec6a34f",
   "metadata": {
    "id": "90338168-0d47-42a2-8f79-32cedec6a34f"
   },
   "outputs": [],
   "source": [
    "# store in grid at node\n",
    "_=grid.add_field('field__capacity', soil_theta_fc, at='node', clobber=True)\n",
    "_=grid.add_field('wilting__point', soil_theta_wp, at='node', clobber=True)\n",
    "_=grid.add_field('porosity', soil_porosity, at='node', clobber=True)\n",
    "_=grid.add_field('soil__internal_friction_angle', internal_friction_angle, at='node', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65166679-29ea-49d5-a481-2025f71c733f",
   "metadata": {
    "id": "65166679-29ea-49d5-a481-2025f71c733f",
    "outputId": "350a12c7-b9ad-4776-d908-15f058689f33"
   },
   "outputs": [],
   "source": [
    "# Store in output directory as ASCII\n",
    "write_esri_ascii(os.path.join(output_dir, 'field__capacity.asc'), grid, 'field__capacity', clobber=True)\n",
    "write_esri_ascii(os.path.join(output_dir, 'wilting__point.asc'), grid, 'wilting__point', clobber=True)\n",
    "write_esri_ascii(os.path.join(output_dir, 'porosity.asc'), grid, 'porosity', clobber=True)\n",
    "write_esri_ascii(os.path.join(output_dir, 'soil__internal_friction_angle.asc'), grid, 'soil__internal_friction_angle', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff75ffe-0fae-4ab0-bd2d-85d2c6de86bc",
   "metadata": {
    "id": "5ff75ffe-0fae-4ab0-bd2d-85d2c6de86bc"
   },
   "outputs": [],
   "source": [
    "# calculate soil density as a function of dry bulk density and porosity\n",
    "# store in grid at node\n",
    "_=grid.add_field('soil__density', (grid.at_node['dry__bulk_density']/(1 - grid.at_node['porosity']))*1000, at='node', clobber=True) #kg/m^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469f63a-7de7-49c6-a65f-0daaba97df68",
   "metadata": {
    "id": "a469f63a-7de7-49c6-a65f-0daaba97df68",
    "outputId": "3aa5b32b-4c61-44ce-c30a-bb981188ff6e"
   },
   "outputs": [],
   "source": [
    "# Store in output directory as ASCII\n",
    "write_esri_ascii(os.path.join(output_dir, 'soil__density.asc'), grid, 'soil__density', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c3d51c-4cdd-42ec-8965-69bc78211afb",
   "metadata": {
    "id": "51c3d51c-4cdd-42ec-8965-69bc78211afb"
   },
   "outputs": [],
   "source": [
    "# simplify NLCS land cover classifications to bare/developed, forest, shrub, herbaceous/grassy, wetland\n",
    "def rootcohesion(C, nd, b, f, s, h, w):\n",
    "    nC = []\n",
    "    for i in C:\n",
    "        if i == 250:\n",
    "            nC.append(nd)\n",
    "        elif i in [12, 21, 22, 23, 24, 31]:\n",
    "            nC.append(b) # bare/developed\n",
    "        elif i in [41, 42, 43]:\n",
    "            nC.append(f) # forest\n",
    "        elif i in [51, 52]:\n",
    "            nC.append(s) # shrub\n",
    "        elif i in [71, 72, 73, 74, 81, 82]:\n",
    "            nC.append(h) # herbaceous\n",
    "        elif i in [90, 95]:\n",
    "            nC.append(w) # wetland\n",
    "        else:\n",
    "            nC.append(nd)\n",
    "    return nC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7363bd7-cc88-431d-b94f-56ef06cd2e8f",
   "metadata": {
    "id": "f7363bd7-cc88-431d-b94f-56ef06cd2e8f"
   },
   "outputs": [],
   "source": [
    "nC = rootcohesion(C,0,1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49f003-f2b9-4c3e-be9c-aa08cb8ff1bb",
   "metadata": {
    "id": "cf49f003-f2b9-4c3e-be9c-aa08cb8ff1bb",
    "outputId": "e455ad66-1814-4ccd-ae96-f2795bd2ffe9"
   },
   "outputs": [],
   "source": [
    "# store at node in grid\n",
    "grid.add_field('landcovercolor', nC, at='node', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3f4f7-0a71-41b3-827c-b6ee2d19e154",
   "metadata": {
    "id": "f6c3f4f7-0a71-41b3-827c-b6ee2d19e154"
   },
   "outputs": [],
   "source": [
    "# increase soil internal friction angle by 3 degrees at developed cells to account for compression\n",
    "for i in range(len(grid.at_node['landcover'])):\n",
    "    if grid.at_node['landcover'][i] in [21, 22, 23, 24]:\n",
    "        grid.at_node['soil__internal_friction_angle'][i] += 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453a0d1-dd1d-46af-b55d-78f5e0d6cdb4",
   "metadata": {
    "id": "0453a0d1-dd1d-46af-b55d-78f5e0d6cdb4"
   },
   "outputs": [],
   "source": [
    "# assign cohesion values (Pa) based on land cover classification according to Strauch et al. (2018)\n",
    "C_min = rootcohesion(C,-9999.,30, 4000, 2000, 1000, 3000)\n",
    "C_mode = rootcohesion(C,-9999.,100, 10000, 4000, 2000, 6000)\n",
    "C_max = rootcohesion(C,-9999.,150, 20000, 10000, 5000, 14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d1121-b2f8-4197-ae4d-63666d9eaf6d",
   "metadata": {
    "id": "a95d1121-b2f8-4197-ae4d-63666d9eaf6d",
    "outputId": "34b58f83-88bf-4e1a-c25b-aad373a3f7e2"
   },
   "outputs": [],
   "source": [
    "# store in grid at node\n",
    "grid.add_field('soil__minimum_total_cohesion', C_min, at='node', clobber=True)\n",
    "grid.add_field('soil__maximum_total_cohesion', C_max, at='node', clobber=True)\n",
    "grid.add_field('soil__mode_total_cohesion', C_mode, at='node', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b10252-cd33-497e-9955-efd44916bfb8",
   "metadata": {
    "id": "26b10252-cd33-497e-9955-efd44916bfb8",
    "outputId": "0596051e-f0b7-4ef4-d276-58a887cad479"
   },
   "outputs": [],
   "source": [
    "# Store in output directory as ASCII\n",
    "write_esri_ascii(os.path.join(output_dir, 'soil__minimum_total_cohesion.asc'), grid, 'soil__minimum_total_cohesion', clobber=True)\n",
    "write_esri_ascii(os.path.join(output_dir, 'soil__maximum_total_cohesion.asc'), grid, 'soil__maximum_total_cohesion', clobber=True)\n",
    "write_esri_ascii(os.path.join(output_dir, 'soil__mode_total_cohesion.asc'), grid, 'soil__mode_total_cohesion', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929144b-df99-4c41-8707-9774b390bb8a",
   "metadata": {
    "id": "6929144b-df99-4c41-8707-9774b390bb8a"
   },
   "outputs": [],
   "source": [
    "# simple conversion from NLCS land cover classifications to vegetation type\n",
    "def vegtype(C, nd, bare, tree, shrub, grass):\n",
    "    vC = []\n",
    "    for i in C:\n",
    "        if i == 250:\n",
    "            vC.append(nd)\n",
    "        elif i in [12, 21, 22, 23, 24, 31]:        # Bare\n",
    "            vC.append(bare)\n",
    "        elif i in [41, 42, 43, 90]:                # Tree (includes woody wetlands)\n",
    "            vC.append(tree)\n",
    "        elif i in [51, 52]:                        # Shrub/Scrub\n",
    "            vC.append(shrub)\n",
    "        elif i in [71, 72, 73, 74, 81, 82, 95]:    # Grass types + herbaceous wetlands\n",
    "            vC.append(grass)\n",
    "        else:\n",
    "            vC.append(nd)\n",
    "    return vC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ba1c5-bdd4-451a-93bb-afbdeec7aaed",
   "metadata": {
    "id": "9e5ba1c5-bdd4-451a-93bb-afbdeec7aaed"
   },
   "outputs": [],
   "source": [
    "vegetation_type = vegtype(C,-9999.,3, 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54578e47-d40e-4f3c-b913-678c50694a40",
   "metadata": {
    "id": "54578e47-d40e-4f3c-b913-678c50694a40",
    "outputId": "cb6ddd16-be6f-4c2f-e3f9-58f1729edf04"
   },
   "outputs": [],
   "source": [
    "# store in grid at node\n",
    "grid.add_field('vegetation__plant_functional_type', vegetation_type, at='node', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0158d2-51ef-4c25-8f73-0f9f78fbb39b",
   "metadata": {
    "id": "3d0158d2-51ef-4c25-8f73-0f9f78fbb39b",
    "outputId": "b82b2920-9324-4979-f1be-e2fd677c3803"
   },
   "outputs": [],
   "source": [
    "# Store in output directory as ASCII\n",
    "write_esri_ascii(os.path.join(output_dir, 'vegetation__plant_functional_type.asc'), grid, 'vegetation__plant_functional_type', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd887862-529c-474d-b939-c4faf6313897",
   "metadata": {
    "id": "dd887862-529c-474d-b939-c4faf6313897",
    "outputId": "a2ac0482-6dd8-4ddf-c174-b457c8f14f95"
   },
   "outputs": [],
   "source": [
    "imshow_grid(grid,'topographic__elevation', plot_name = 'Elevation',\n",
    "            var_name = 'Elevation', var_units = 'm', grid_units = ('m','m'),\n",
    "            cmap = 'terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa52596-ee21-49f4-89f9-b75e52471885",
   "metadata": {
    "id": "1fa52596-ee21-49f4-89f9-b75e52471885",
    "outputId": "f145f768-0604-4c0c-feb4-7a1b8fe1fa30"
   },
   "outputs": [],
   "source": [
    "imshow_grid(grid,'soil__thickness', plot_name = 'Soil Thickness',\n",
    "            var_name = 'Soil thickness', var_units = 'm', grid_units = ('m','m'),\n",
    "            cmap = 'copper_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ae17d-d319-4e63-b27b-070cd2ca5d92",
   "metadata": {
    "id": "823ae17d-d319-4e63-b27b-070cd2ca5d92",
    "outputId": "a44fe55c-de8e-470b-c53e-2e3399d9e09f"
   },
   "outputs": [],
   "source": [
    "imshow_grid_at_node(grid, 'burn__severity', plot_name = 'Burn Severity',\n",
    "            cmap = ListedColormap(['green',\"blue\", \"yellow\", \"red\"], N=4), limits = (0.5,4.5), allow_colorbar= False)\n",
    "cb = plt.colorbar()\n",
    "cb.set_ticks([1,2,3,4])\n",
    "cb.set_ticklabels(['Unburned/Unmapped', 'Low','Medium','High'])\n",
    "plt.title('Burn Severity', fontweight='bold')\n",
    "plt.xlabel('X (m)', fontweight='bold')\n",
    "plt.ylabel('Y (m)', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec931eb-0d9b-469b-929a-f4f2e7f227fc",
   "metadata": {
    "id": "8ec931eb-0d9b-469b-929a-f4f2e7f227fc",
    "outputId": "6cc9868c-3c87-4b30-8117-a62b63981638"
   },
   "outputs": [],
   "source": [
    "imshow_grid(grid,'soil__texture', plot_name = 'soil__texture',\n",
    "            var_name = 'Ksat', var_units = 'm/day', grid_units = ('m','m'),\n",
    "            cmap = 'gist_earth_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc6473-149a-456a-ac4e-99503983c929",
   "metadata": {
    "id": "89dc6473-149a-456a-ac4e-99503983c929",
    "outputId": "97498e6f-bbcf-406c-c3f1-df4ae175df39"
   },
   "outputs": [],
   "source": [
    "imshow_grid_at_node(grid, 'soil__texture', plot_name = 'Soil Texture',\n",
    "            cmap = ListedColormap(['k',\"blue\", \"orange\", \"green\", \"pink\", \"red\",\n",
    "                        \"slategray\", \"cyan\", \"white\", \"darkkhaki\", \"purple\", \"yellow\", 'brown'], N=13), limits = (-0.5,12.5), allow_colorbar= False)\n",
    "cb = plt.colorbar()\n",
    "cb.set_ticks([0,1,2,3,4,5,6,7,8,9, 10, 11, 12])\n",
    "cb.set_ticklabels(['Unclassified', 'Sand','Loamy Sand','Sandy Loam','Loam','Silt Loam', 'Silt',\n",
    "                  'Sandy Clay Loam','Clay Loam', 'Silty Clay Loam','Sandy Clay', 'Silty Clay', 'Clay'])\n",
    "plt.title('Soil Texture', fontweight='bold')\n",
    "plt.xlabel('X (m)', fontweight='bold')\n",
    "plt.ylabel('Y (m)', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6d496-a8aa-40d3-ab23-ea96c7ab4a2a",
   "metadata": {
    "id": "f8c6d496-a8aa-40d3-ab23-ea96c7ab4a2a",
    "outputId": "c7de7fbd-2a5e-4274-fde4-abe9c7c835d7"
   },
   "outputs": [],
   "source": [
    "imshow_grid_at_node(grid, 'landcover', plot_name = 'Burmapinar Landcover Classifications',\n",
    "            cmap = ListedColormap(['k',\"blue\", \"springgreen\", \"green\", \"orange\", \"red\",\n",
    "                        \"slategray\", \"cyan\", \"white\", \"darkkhaki\"], N=6), limits = (-0.5,5.5), allow_colorbar= False)\n",
    "cb = plt.colorbar()\n",
    "cb.set_ticks([0,1,2,3,4,5])\n",
    "cb.set_ticklabels(['No Data', 'Bare', 'forest', 'shrub', 'herbaceous', 'wetland'])\n",
    "plt.title('Land Cover (LULC-ESRI)', fontweight='bold')\n",
    "plt.xlabel('X (m)', fontweight='bold')\n",
    "plt.ylabel('Y (m)', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from landlab.io import esri_ascii\n",
    "\n",
    "lc_path = \"/mnt/c/Users/amehedi/Downloads/ml_debris/output/landcover.asc\"\n",
    "\n",
    "with open(lc_path, \"r\") as f:\n",
    "    grid = esri_ascii.load(f, name=\"landcover\")\n",
    "\n",
    "landcover = grid.at_node[\"landcover\"]\n",
    "landcover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(landcover[~np.isnan(landcover)])[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "lc = landcover.copy()\n",
    "lc = np.where(lc == 250, np.nan, lc)\n",
    "\n",
    "lulc = np.full_like(lc, np.nan, dtype=float)\n",
    "lulc[np.isin(lc, [12, 21, 22, 23, 24, 31])] = 1  # Bare/Developed\n",
    "lulc[np.isin(lc, [41, 42, 43])] = 2              # Forest\n",
    "lulc[np.isin(lc, [51, 52])] = 3                  # Shrub\n",
    "lulc[np.isin(lc, [71, 72, 73, 74, 81, 82])] = 4  # Herbaceous\n",
    "lulc[np.isin(lc, [90, 95])] = 5                  # Wetland\n",
    "\n",
    "cmap = ListedColormap([\"#1f77b4\", \"#2ca02c\", \"#98df8a\", \"#ffbb78\", \"#d62728\"])\n",
    "bounds = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(lulc.reshape(grid.shape), cmap=cmap, norm=norm, origin=\"lower\")\n",
    "cb = plt.colorbar(ticks=[1, 2, 3, 4, 5])\n",
    "cb.set_ticklabels([\"Bare\", \"Forest\", \"Shrub\", \"Herbaceous\", \"Wetland\"])\n",
    "plt.title(\"Land Cover (Reclassified)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27028de-8704-4ec7-9e85-12163953b8ed",
   "metadata": {
    "id": "f27028de-8704-4ec7-9e85-12163953b8ed",
    "outputId": "1d83f8c2-f5ca-4480-c35a-17d64811875a"
   },
   "outputs": [],
   "source": [
    "imshow_grid_at_node(grid,'soil__mode_total_cohesion', plot_name = 'Mode cohesion',\n",
    "            var_name = 'Soil Cohesion', var_units = 'Pa', grid_units = ('m','m'),\n",
    "            cmap = 'Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ced33d-e562-474e-a470-0129f93e7e2f",
   "metadata": {
    "id": "d0ced33d-e562-474e-a470-0129f93e7e2f",
    "outputId": "ba5e16c0-31d9-4f9f-e396-80c800fa971d"
   },
   "outputs": [],
   "source": [
    "imshow_grid_at_node(grid, 'vegetation__plant_functional_type', plot_name = 'Vegetation Type',\n",
    "            cmap = ListedColormap(['pink',\"darkkhaki\", \"springgreen\", \"red\"], N=4), limits = (-0.5,3.5), allow_colorbar= False)\n",
    "cb = plt.colorbar()\n",
    "cb.set_ticks([0,1,2,3])\n",
    "cb.set_ticklabels(['grass', 'shrub','tree','bare'])\n",
    "plt.title('Vegetation Type', fontweight='bold')\n",
    "plt.xlabel('X (m)', fontweight='bold')\n",
    "plt.ylabel('Y (m)', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab421f-ddb9-4b52-aea4-6a91d4de4fc7",
   "metadata": {
    "id": "02ab421f-ddb9-4b52-aea4-6a91d4de4fc7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ff330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ml_debris)",
   "language": "python",
   "name": "ml_debris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
